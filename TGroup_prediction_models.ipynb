{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import metrics \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data from file as a dataframe\n",
    "def read_data():  \n",
    "    data_file = open(\"data_2018.txt\",\"r\")\n",
    "    data_file1 = open(\"data_2017.txt\",\"r\")\n",
    "    data_file2 = open(\"data_2016.txt\",\"r\")\n",
    "    file_content = data_file.read()\n",
    "    file_content1 = data_file1.read()\n",
    "    file_content2 = data_file2.read()\n",
    "    json_data = json.loads(file_content)\n",
    "    json_data1 = json.loads(file_content1)\n",
    "    json_data2 = json.loads(file_content2)\n",
    "    json_data+=json_data1\n",
    "    json_data+=json_data2\n",
    "    df = pd.DataFrame(json_data)\n",
    "#     data_file = open(\"data_2018.txt\",\"r\")\n",
    "#     file_content = data_file.read()\n",
    "#     json_data = json.loads(file_content)\n",
    "#     df = pd.DataFrame(json_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with selected column list,\n",
    "# and make some filters on dataframe 'price' > 0 and 'TGroup' == specific value passed by user\n",
    "def select_columns(df,column_list):\n",
    "    new_df = df[column_list]\n",
    "    new_df = new_df.loc[(new_df['Price'] > 0) & (df[\"SStatus\"]==\"For Sale\")]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df,column,value):\n",
    "    if column == \"Floor\":\n",
    "        df.replace('N/A', np.nan,inplace=True)\n",
    "    else:\n",
    "        df.replace('', np.nan,inplace=True)\n",
    "    if value is None:\n",
    "        value = \"None\"\n",
    "    df[column]=df[column].fillna(value)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelized all the columns of dataframe\n",
    "# def labelized_data(df):\n",
    "#     for c in df.columns:\n",
    "#         if df[c].dtype == \"object\":\n",
    "#             lbl = preprocessing.LabelEncoder()\n",
    "#             lbl.fit(list(df[c].values))\n",
    "#             df[c] = lbl.transform(list(df[c].values))\n",
    "#     return df\n",
    "\n",
    "def labelized_data(df):\n",
    "    from sklearn import preprocessing\n",
    "    all_label_encoders = {}\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            print(\"c\",c)\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(df[c].values))\n",
    "            df[c] = lbl.transform(list(df[c].values))\n",
    "            all_label_encoders[c] = lbl\n",
    "    pickle.dump(all_label_encoders,open(\"all_label_encoders.dict\",\"wb\"))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates X and Y\n",
    "def create_x_y(new_df):\n",
    "    X = new_df.drop(\"Price\",axis=1)\n",
    "    Y = new_df[\"Price\"]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply fit and calculate prediction and return mae\n",
    "def check_models(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mean_absolute_error = metrics.mean_absolute_error(y_test, y_pred)    \n",
    "    print('mean_absolute_error',mean_absolute_error)\n",
    "    return mean_absolute_error,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_models_mae(models,X_train, X_test, y_train, y_test):\n",
    "    m={}\n",
    "#     models_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        print(\"Applying \",model)\n",
    "        model_m,y_pred = check_models(models.get(model),X_train, X_test, y_train, y_test)\n",
    "        m[model] = model_m\n",
    "#         models_df[model+\"_y_pred\"] = list(y_pred)\n",
    "#         print('y test',list(y_test))\n",
    "#         models_df[model+\"_y_test\"] = list(y_test)\n",
    "#     models_df.to_csv('models_predictions.csv')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_models(models_mae):\n",
    "    k = Counter(models_mae)\n",
    "    top_most = k.most_common()[:-3:-1]\n",
    "    top = []\n",
    "    for t in top_most:\n",
    "        top.append(t[0])\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowest_model(models_mae):\n",
    "    return min(models_mae, key=models_mae.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_list():\n",
    "    GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.1,\n",
    "                                   max_depth=7, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='lad', random_state =48)\n",
    "    models={\"GBoost\":GBoost}\n",
    "#     rfr = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "#     model_xgb = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#            colsample_bytree=0.2, gamma=0.0, importance_type='gain',\n",
    "#            learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
    "#            min_child_weight=1.5, missing=None, n_estimators=7200, n_jobs=1,\n",
    "#            nthread=None, objective='reg:linear', random_state=42,\n",
    "#            reg_alpha=0.1, reg_lambda=0.1, scale_pos_weight=1, seed=42,\n",
    "#            silent=1, subsample=0.1)\n",
    "\n",
    "#     model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "#                                   learning_rate=0.05, n_estimators=720,\n",
    "#                                   max_bin = 55, bagging_fraction = 0.8,\n",
    "#                                   bagging_freq = 5, feature_fraction = 0.2319,\n",
    "#                                   feature_fraction_seed=9, bagging_seed=9,\n",
    "#                                   min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "    \n",
    "#     lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "    \n",
    "#     ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "    \n",
    "#     KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "#     models = {\"GBoost\":GBoost,\"rfr\":rfr,\"model_xgb\":model_xgb,\"model_lgb\":model_lgb,\"lasso\":lasso,\"ENet\":ENet,\"KRR\":KRR}\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_area_value(row):\n",
    "    if row['FArea']>row['PArea']:\n",
    "        return row['FArea']\n",
    "    elif row['PArea']>row['FArea']:\n",
    "        return row['PArea']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def merge_area(df):\n",
    "    df['Area'] = df.apply(get_area_value,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "this is the main function for each TGroup where you have to pass one 'group' from [\"C\",\"F\",\"G\",\"H\",\"M\",\"O\",\"P\",\"T\",\"V\"]\n",
    "and a column list for the group given that must include two columns \"Price\" and \"TGroup\".\n",
    "'''\n",
    "def main(column_list):\n",
    "    # read data from file as dataframe.\n",
    "    df = read_data()\n",
    "    \n",
    "    # get only those columns mention in column_list.\n",
    "    df = select_columns(df,column_list)\n",
    "    \n",
    "    df = merge_area(df)\n",
    "    drop_columns = ['FArea','PArea','SStatus']\n",
    "    df.drop(drop_columns,axis=1,inplace=True)\n",
    "    for d in drop_columns:\n",
    "        column_list.remove(d)\n",
    "        \n",
    "    # replace all blank cells by None from dataframe.\n",
    "    missing_values = {\"Floor\":\"No Floor\",\"Views\":\"no Views\",\"Form\":\"no Form\"}\n",
    "    for col in column_list:\n",
    "        df = fill_missing_values(df,col,missing_values.get(col))\n",
    "        \n",
    "    # labelizing the column values if it is not int or float.\n",
    "    df = labelized_data(df)\n",
    "    \n",
    "    # creates X and Y dataframe.\n",
    "    X,Y = create_x_y(df)\n",
    "    \n",
    "    # creates X_train, X_test, y_train and y_test.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # create following models object in a dictionary\n",
    "    # [GradientBoostingRegressor, RandomForestRegressor, XGBRegressor, LGBMRegressor, Lasso, ElasticNet, KernelRidge] \n",
    "    models = get_models_list()\n",
    "    \n",
    "    # fit, predict price, and calculate mean absolute error for each model and return as a dictionary\n",
    "    models_mae = calc_models_mae(models,X_train, X_test, y_train, y_test)\n",
    "    \n",
    "#     # get 2 models that have lowest mean absolute error\n",
    "#     average_models = get_top_models(models_mae)\n",
    "    \n",
    "#     # creates object of AveragingModels class by with your 2 lowest value models\n",
    "#     averaged_models = AveragingModels(models=(models.get(average_models[0]),models.get(average_models[1])))\n",
    "    \n",
    "#     # fit, predict price, and calculate mean absolute error for 2 lowest value models\n",
    "#     print(\"Average of 2 top models\")\n",
    "#     average_pred,y_pred = check_models(averaged_models,X_train, X_test, y_train, y_test)\n",
    "#     models_mae['average'] = average_pred\n",
    "    \n",
    "#     # getting lowest mean error value model\n",
    "#     if models_mae.get(average_models[0]) < models_mae.get('average'):\n",
    "#         lowest_value_model = average_models[0]\n",
    "#     elif models_mae.get(average_models[0]) > models_mae.get('average'):\n",
    "#         lowest_value_model = 'average'\n",
    "        \n",
    "    # model name\n",
    "#     model_name = lowest_value_model+\".sav\"\n",
    "    model_name = \"GBoost_model.sav\"\n",
    "    \n",
    "    # saving model\n",
    "    print('model ',model_name,\" saving...\")\n",
    "    pickle.dump(models.get(\"GBoost\"), open(model_name, 'wb'))\n",
    "    \n",
    "    return models_mae\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c Location\n",
      "c Floor\n",
      "c Form\n",
      "c Type\n",
      "c Views\n",
      "Applying  GBoost\n",
      "mean_absolute_error 186108.2959541833\n",
      "model  GBoost_model.sav  saving...\n",
      "{'GBoost': 186108.2959541833}\n"
     ]
    }
   ],
   "source": [
    "column_list = [\"Bedrooms\",\"Location\",\"Cars\",\"Floor\",\"Form\",\"Type\",\"Views\",\"FArea\",\"PArea\",\"Price\",\"SStatus\"]\n",
    "output = main(column_list)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying  GBoost\n",
      "mean_absolute_error 186108.2959541833\n",
      "model  GBoost_model.sav  saving...\n"
     ]
    }
   ],
   "source": [
    "column_list = [\"Bedrooms\",\"Location\",\"Cars\",\"Floor\",\"Form\",\"Type\",\"Views\",\"FArea\",\"PArea\",\"Price\",\"SStatus\"]\n",
    "output = main(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_blank_nan(new_df):\n",
    "    count_nan=new_df.isnull().sum(axis=0)\n",
    "    empty_count = new_df.replace('',np.nan).isnull().sum(axis=0)\n",
    "    nan_attributes = count_nan.to_dict()\n",
    "    empty_count = empty_count.subtract(count_nan, axis=0)\n",
    "    empty_attributes = empty_count.to_dict()\n",
    "    return empty_attributes,nan_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main2(group,file):\n",
    "    df = read_data()\n",
    "    drop_column_list = [\"Board\", \"CArea\", \"DateInserted\",\"SaleWriteup\",\\\n",
    "                    \"AvailableDate\",\"Yearly\",\"RightToBuild\",\"OnPlan\",\\\n",
    "                   \"Declaration\",\"CStatus\",\"Keys\",\"Ref\",\"Street\",\"UpdDate\",\\\n",
    "                   \"InspDate\",\"GREDate\",\"PropertyAmendments\",\\\n",
    "                    \"PropertyDetails\",\"PlanNo\", \"SDate\", \"LeaseWriteup\",\\\n",
    "                    \"ClientSignature\", \"LStatus\", \"LDate\", \"CStatus\", \\\n",
    "                    \"Premium\", \"Valuation\", \"PriceSqMtr\", \"Signed\",\"Regulation\",\"TypeOfConstr\",\\\n",
    "                   ]\n",
    "    new_df = df.drop(drop_column_list,axis=1)\n",
    "    new_df = new_df.loc[(new_df['Price'] > 0) & (new_df['TGroup'] == group) & (new_df['SStatus'] == \"For Sale\")]\n",
    "    total = len(new_df.index)\n",
    "    empty,nan=count_blank_nan(new_df)\n",
    "    floor_Df = len(new_df.loc[new_df['Floor']==\"N/A\"].index)\n",
    "    bedroom_df = len(new_df.loc[new_df['Bedrooms']==0].index)\n",
    "    cars_df = len(new_df.loc[new_df['Cars']==0].index)\n",
    "    daily_df = len(new_df.loc[new_df['Daily']==0].index)\n",
    "    grent_df = len(new_df.loc[new_df['GRent']==0].index)\n",
    "    gprice_df = len(new_df.loc[new_df['GarPrice']==0].index)\n",
    "    monthly = len(new_df.loc[new_df['Monthly']==0].index)\n",
    "    PArea = len(new_df.loc[new_df['PArea']==0].index)\n",
    "    \n",
    "    data=[empty,nan,{\"Floor\":floor_Df},{\"Bedrooms\":bedroom_df,\"Cars\":cars_df,\"PArea\":PArea,\\\n",
    "                                                   \"Daily\":daily_df,\"GRent\":grent_df,\\\n",
    "                                                  \"GarPrice\":gprice_df,\"Monthly\":monthly},{\"Bedrooms\":total}]\n",
    "    df = pd.DataFrame(data,index = ['blank','nan','N/A','0','total'])\n",
    "\n",
    "    df.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[]\n",
    "for typeg in ['C','F','G','H','M','O','P','T','V']:\n",
    "    file = \"group_\"+typeg+\".csv\"\n",
    "    main2(typeg,file)\n",
    "    files.append(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_merge = open(\"all_group.csv\", 'w')\n",
    "\n",
    "for file in files:\n",
    "    csv_in = open(file)\n",
    "    csv_merge.write(file.split('.')[0])\n",
    "    for line in csv_in:\n",
    "        csv_merge.write(line)\n",
    "    csv_merge.write('\\n')\n",
    "    csv_in.close()\n",
    "csv_merge.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying  rfr\n",
      "mean_absolute_error 58138.740204471236\n",
      "Applying  model_lgb\n",
      "mean_absolute_error 74864.29151806787\n",
      "Applying  GBoost\n",
      "mean_absolute_error 50068.40186224562\n",
      "Applying  KRR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vantena/surefit/testing/code2/venv/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:165: LinAlgWarning: Ill-conditioned matrix (rcond=2.55268e-21): result may not be accurate.\n",
      "  overwrite_a=False)\n",
      "/home/vantena/surefit/testing/code2/venv/lib/python3.5/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error 103625.06836916365\n",
      "Applying  lasso\n",
      "mean_absolute_error 121955.15116598991\n",
      "Applying  model_xgb\n",
      "mean_absolute_error 79203.73418397724\n",
      "Applying  ENet\n",
      "mean_absolute_error 121954.24270625929\n",
      "Average of 2 top models\n"
     ]
    }
   ],
   "source": [
    "# few examples are here\n",
    "column_list = [\"Form\",\"Bedrooms\",\"Location\",\"TGroup\",\"Floor\",\"FArea\",\"Price\"]\n",
    "group = \"F\"\n",
    "output = main(column_list,group)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying  rfr\n",
      "mean_absolute_error 51414.8287938913\n",
      "Applying  model_lgb\n",
      "mean_absolute_error 54050.451515636705\n",
      "Applying  GBoost\n",
      "mean_absolute_error 51864.23422085096\n",
      "Applying  KRR\n",
      "mean_absolute_error 67840.61450859367\n",
      "Applying  lasso\n",
      "mean_absolute_error 70893.55832471915\n",
      "Applying  model_xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vantena/surefit/testing/code2/venv/lib/python3.5/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error 62431.133138020836\n",
      "Applying  ENet\n",
      "mean_absolute_error 70892.97146192957\n",
      "Average of 2 top models\n",
      "mean_absolute_error 49793.75857561299\n",
      "{'ENet': 70892.97146192957, 'rfr': 51414.8287938913, 'model_lgb': 54050.451515636705, 'average': 49793.75857561299, 'GBoost': 51864.23422085096, 'KRR': 67840.61450859367, 'lasso': 70893.55832471915, 'model_xgb': 62431.133138020836}\n"
     ]
    }
   ],
   "source": [
    "column_list = [\"Price\",\"TGroup\",\"Cars\",\"Form\",\"Garage\",\"Location\",\"PArea\",\"Bedrooms\",\"Floor\",\"Views\"]\n",
    "group = \"M\"\n",
    "output = main(column_list,group)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying  rfr\n",
      "mean_absolute_error 944507.0976702508\n",
      "Applying  model_lgb\n",
      "mean_absolute_error 871709.7004595605\n",
      "Applying  GBoost\n",
      "mean_absolute_error 541296.6334807018\n",
      "Applying  KRR\n",
      "mean_absolute_error 1049066.3287387125\n",
      "Applying  lasso\n",
      "mean_absolute_error 894255.5927289847\n",
      "Applying  model_xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vantena/surefit/testing/code2/venv/lib/python3.5/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error 1355802.2283266129\n",
      "Applying  ENet\n",
      "mean_absolute_error 894232.2679416342\n",
      "Average of 2 top models\n",
      "mean_absolute_error 692249.418000178\n",
      "{'ENet': 894232.2679416342, 'rfr': 944507.0976702508, 'model_lgb': 871709.7004595605, 'average': 692249.418000178, 'GBoost': 541296.6334807018, 'KRR': 1049066.3287387125, 'lasso': 894255.5927289847, 'model_xgb': 1355802.2283266129}\n"
     ]
    }
   ],
   "source": [
    "column_list = [\"Price\",\"TGroup\",\"Form\",\"Location\",\"PArea\",\"Floor\",\"Views\"]\n",
    "group = \"C\"\n",
    "output = main(column_list,group)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
